{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2107e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformed line in minirocket_result/metrics.txt: \n",
      "Skipping malformed line in minirocket_result/metrics.txt: Average LOPOCV Accuracy: 46.29%\n",
      "Skipping malformed line in minirocket_result/metrics.txt: Average LOPOCV F1 Score: 43.45%\n",
      "Skipping malformed line in convtran_result/metrics_best.txt: \n",
      "Skipping malformed line in convtran_result/metrics_best.txt: Average LOPOCV Accuracy: 46.98%\n",
      "Skipping malformed line in convtran_result/metrics_best.txt: Average LOPOCV F1 Score: 41.98%\n",
      "Skipping malformed line in s4d_result/metrics.txt: \n",
      "Skipping malformed line in s4d_result/metrics.txt: Average LOPOCV Accuracy: 46.78%\n",
      "Skipping malformed line in s4d_result/metrics.txt: Average LOPOCV F1 Score: 39.74%\n",
      "MiniRocket vs ConvTran:\n",
      "T-statistic (Accuracy): -0.23363657784130473, P-value: 0.8186488694654932\n",
      "T-statistic (F1 Score): 0.5810582554094299, P-value: 0.570437924541577\n",
      "\n",
      "MiniRocket vs S4D:\n",
      "T-statistic (Accuracy): -0.17906430770447998, P-value: 0.8604528015482578\n",
      "T-statistic (F1 Score): 1.375682277685192, P-value: 0.19053134228173674\n",
      "\n",
      "MiniRocket vs ConvTran:\n",
      "T-statistic (Accuracy): -0.23363657784130473, P-value: 0.8186488694654932\n",
      "T-statistic (F1 Score): 0.5810582554094299, P-value: 0.570437924541577\n",
      "No significant difference in Accuracy between MiniRocket and ConvTran.\n",
      "No significant difference in F1 Score between MiniRocket and ConvTran.\n",
      "\n",
      "MiniRocket vs S4D:\n",
      "T-statistic (Accuracy): -0.17906430770447998, P-value: 0.8604528015482578\n",
      "T-statistic (F1 Score): 1.375682277685192, P-value: 0.19053134228173674\n",
      "No significant difference in Accuracy between MiniRocket and S4D.\n",
      "No significant difference in F1 Score between MiniRocket and S4D.\n",
      "\n",
      "MiniRocket vs KNN:\n",
      "T-statistic (Accuracy): -11.11863632568215, P-value: 2.474174971673898e-08\n",
      "T-statistic (F1 Score): 1.375682277685192, P-value: 0.19053134228173674\n",
      "Significant difference in Accuracy between MiniRocket and KNN.\n",
      "No significant difference in F1 Score between MiniRocket and KNN.\n",
      "\n",
      "MiniRocket vs XGBoost:\n",
      "T-statistic (Accuracy): -11.121737469129865, P-value: 2.4654522972134087e-08\n",
      "T-statistic (F1 Score): 2.082239749334463, P-value: 0.05614574998825482\n",
      "Significant difference in Accuracy between MiniRocket and XGBoost.\n",
      "No significant difference in F1 Score between MiniRocket and XGBoost.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "def load_metrics(file_path):\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "\n",
    "    in_accuracy_section = False\n",
    "    in_f1_section = False\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Check if the line starts a new section\n",
    "            if \"Accuracies:\" in line:\n",
    "                in_accuracy_section = True\n",
    "                in_f1_section = False  # Disable F1 section\n",
    "                continue  # Skip this line\n",
    "\n",
    "            elif \"F1 Scores:\" in line:\n",
    "                in_f1_section = True\n",
    "                in_accuracy_section = False  # Disable Accuracy section\n",
    "                continue  # Skip this line\n",
    "\n",
    "            # Collect numerical values from the appropriate sections\n",
    "            try:\n",
    "                if in_accuracy_section:\n",
    "                    accuracies.append(float(line.strip()))\n",
    "\n",
    "                elif in_f1_section:\n",
    "                    f1_scores.append(float(line.strip()))\n",
    "\n",
    "            except ValueError:\n",
    "                # Skip any non-numeric lines\n",
    "                print(f\"Skipping malformed line in {file_path}: {line.strip()}\")\n",
    "\n",
    "    return np.array(accuracies), np.array(f1_scores)\n",
    "\n",
    "# Load metrics for each model\n",
    "minirocket_acc, minirocket_f1 = load_metrics('minirocket_result/metrics.txt')\n",
    "convtran_acc, convtran_f1 = load_metrics('convtran_result/metrics_best.txt')\n",
    "s4d_acc, s4d_f1 = load_metrics('s4d_result/metrics.txt')\n",
    "\n",
    "def load_csv_metrics(file_path):\n",
    "    \"\"\"Load accuracy and F1 scores from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df['Accuracy'].values, df['F1_Score'].values\n",
    "\n",
    "# Load metrics for KNN and XGBoost from wavelet features\n",
    "knn_acc, knn_f1 = load_csv_metrics('wavelet_result/knn_result.csv')\n",
    "xgboost_acc, xgboost_f1 = load_csv_metrics('wavelet_result/xgboost_result.csv')\n",
    "\n",
    "# Ensure the arrays are non-empty and of the same length before running t-tests\n",
    "if minirocket_acc.size and convtran_acc.size and minirocket_acc.size == convtran_acc.size:\n",
    "    t_stat_acc, p_value_acc = ttest_rel(minirocket_acc, convtran_acc)\n",
    "    t_stat_f1, p_value_f1 = ttest_rel(minirocket_f1, convtran_f1)\n",
    "\n",
    "    print(\"MiniRocket vs ConvTran:\")\n",
    "    print(f\"T-statistic (Accuracy): {t_stat_acc}, P-value: {p_value_acc}\")\n",
    "    print(f\"T-statistic (F1 Score): {t_stat_f1}, P-value: {p_value_f1}\")\n",
    "\n",
    "if minirocket_acc.size and s4d_acc.size and minirocket_acc.size == s4d_acc.size:\n",
    "    t_stat_acc, p_value_acc = ttest_rel(minirocket_acc, s4d_acc)\n",
    "    t_stat_f1, p_value_f1 = ttest_rel(minirocket_f1, s4d_f1)\n",
    "\n",
    "    print(\"\\nMiniRocket vs S4D:\")\n",
    "    print(f\"T-statistic (Accuracy): {t_stat_acc}, P-value: {p_value_acc}\")\n",
    "    print(f\"T-statistic (F1 Score): {t_stat_f1}, P-value: {p_value_f1}\")\n",
    "\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Function to interpret and print t-test results\n",
    "def report_t_test(model1, model2, t_stat_acc, p_value_acc, t_stat_f1, p_value_f1):\n",
    "    print(f\"\\n{model1} vs {model2}:\")\n",
    "    print(f\"T-statistic (Accuracy): {t_stat_acc}, P-value: {p_value_acc}\")\n",
    "    print(f\"T-statistic (F1 Score): {t_stat_f1}, P-value: {p_value_f1}\")\n",
    "\n",
    "    if p_value_acc < alpha:\n",
    "        print(f\"Significant difference in Accuracy between {model1} and {model2}.\")\n",
    "    else:\n",
    "        print(f\"No significant difference in Accuracy between {model1} and {model2}.\")\n",
    "\n",
    "    if p_value_f1 < alpha:\n",
    "        print(f\"Significant difference in F1 Score between {model1} and {model2}.\")\n",
    "    else:\n",
    "        print(f\"No significant difference in F1 Score between {model1} and {model2}.\")\n",
    "\n",
    "# Report t-test results for MiniRocket vs ConvTran\n",
    "report_t_test(\n",
    "    \"MiniRocket\", \"ConvTran\", \n",
    "    *ttest_rel(minirocket_acc, convtran_acc), \n",
    "    *ttest_rel(minirocket_f1, convtran_f1)\n",
    ")\n",
    "\n",
    "# Report t-test results for MiniRocket vs S4D\n",
    "report_t_test(\n",
    "    \"MiniRocket\", \"S4D\", \n",
    "    *ttest_rel(minirocket_acc, s4d_acc), \n",
    "    *ttest_rel(minirocket_f1, s4d_f1)\n",
    ")\n",
    "\n",
    "report_t_test(\n",
    "    \"MiniRocket\", \"KNN\", \n",
    "    *ttest_rel(minirocket_acc, knn_acc), \n",
    "    *ttest_rel(minirocket_f1, s4d_f1))\n",
    "\n",
    "report_t_test(\n",
    "    \"MiniRocket\", \"XGBoost\", \n",
    "    *ttest_rel(minirocket_acc, xgboost_acc), \n",
    "    *ttest_rel(minirocket_f1, xgboost_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
